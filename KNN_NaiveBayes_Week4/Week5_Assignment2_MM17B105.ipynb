{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week5_Assignment2_MM17B105.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MMWp3bQP-bhU"
      },
      "source": [
        "# Lab 5 - Classification :  k-NN and Naive Bayes (using sklearn libraries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmXrKs6H7UkH",
        "colab_type": "text"
      },
      "source": [
        "## k-NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlIbNohL7UkK",
        "colab_type": "text"
      },
      "source": [
        "Use **\"Pima Indians Diabetes Dataset from UCI Machine Learning Repository\"** for this question.It is a binary class dataset. Split the dataset into train(80%), validation(10%) and test sets(10%).\n",
        "\n",
        "Run k-Nearest neighbours for different k values. Choose your own subset of k (atleast 10) and choose the best value of k from this subset. In solving real-world problems, the values of k are chosen based on experience and hence it is a tunable hyperparameter. Select the k, using validation set, which returns the best accuracy score. Report accuracy score by performing k-NN on the test dataset using the chosen k value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZyyCTI17UkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNhN5xVX9Kzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('diabetes.csv')\n",
        "X=data.drop('Outcome',axis=1)\n",
        "y=data['Outcome']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8OMAkwIBjGE",
        "colab_type": "text"
      },
      "source": [
        "### Train, Validation, Test data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCqeDT-P-A8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=10)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak7KFU94BczU",
        "colab_type": "text"
      },
      "source": [
        "### Maximum validation accuracy is obtained at k=5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS9xu1rL_KEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d56d01a-6c87-47e9-c124-0039ae1851b2"
      },
      "source": [
        "accuracy=[]\n",
        "for i in np.arange(1,100,2):\n",
        "  knn = KNeighborsClassifier(n_neighbors=i)\n",
        "  knn.fit(X_train, y_train) \n",
        "  y_pred= knn.predict(X_val)\n",
        "  accuracy.append((i,accuracy_score(y_pred,y_val)))\n",
        "accuracy.sort(key=lambda x: x[1],reverse=True)\n",
        "print('maximum validation accuracy is obtained at k = '+str(accuracy[0][0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "maximum validation accuracy is obtained at k = 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4FBEQL_1RYM",
        "colab_type": "text"
      },
      "source": [
        "## TEST SET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mloQm8K07rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10f971f1-141d-45c5-e950-fc4e770059be"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train) \n",
        "y_pred= knn.predict(X_test)\n",
        "accuracy=accuracy_score(y_pred,y_test)\n",
        "print('The test set accuracy is ',accuracy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test set accuracy is  0.7142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK4puWp87UkQ",
        "colab_type": "text"
      },
      "source": [
        "# RESULTS\n",
        "\n",
        "**1) The best k value is 5.**\n",
        "\n",
        "**2) The test set accuracy is 0.71428 for k=5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz9M2LOQ7UkR",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZmaWNsr7UkS",
        "colab_type": "text"
      },
      "source": [
        "Use **\"Optical recognition of handwritten digits dataset\"** for this question. ** Download dataset from sklearn**. The dataset has 10 classes and 64 attributes (8x8 images). Visualise images from the dataset. Perform a train test split in the ratio 4:1. \n",
        "\n",
        "Naive Bayes - perform multiclass classification to classify the dataset into one of the ten classes. Experiment with the priors (Gaussian and Bernoulli) and report the best prior. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Qt1V2A7UkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "284fd8b3-2373-4bb1-f1f0-b6b03d5364e2"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)\n",
        "plt.figure(figsize=[10,5])\n",
        "for i in range(10):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.gray()\n",
        "  plt.imshow(digits.images[i]) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27ieAHJlAild",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYttZMA2Xdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=digits.images.reshape(len(digits.images),-1)\n",
        "y=digits.target\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cna11gIcCh-F",
        "colab_type": "text"
      },
      "source": [
        "## Prediction using Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxNwlVk6_xKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "19ee2497-4ab7-4466-9022-3ef0fe019759"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "accuracy=accuracy_score(y_pred,y_test)\n",
        "print('The accuracy is ',accuracy)\n",
        "print('F1 score is ',f1_score(y_test,y_pred,average='weighted'))\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is  0.8472222222222222\n",
            "F1 score is  0.8499421506506554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[34,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
              "       [ 0, 28,  1,  0,  0,  0,  0,  0,  5,  1],\n",
              "       [ 0,  3, 18,  0,  0,  0,  0,  0, 15,  0],\n",
              "       [ 0,  0,  2, 25,  0,  3,  0,  1,  6,  0],\n",
              "       [ 0,  1,  0,  0, 30,  0,  0,  1,  0,  0],\n",
              "       [ 0,  0,  0,  1,  0, 41,  0,  1,  3,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0, 29,  0,  1,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 42,  0,  0],\n",
              "       [ 0,  0,  1,  0,  0,  0,  0,  1, 36,  0],\n",
              "       [ 0,  0,  0,  1,  0,  1,  0,  1,  4, 22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTx3OrjBRqko",
        "colab_type": "text"
      },
      "source": [
        "## Prediction using Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQdtSBBGAzq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "7e9ccd39-cba5-499f-a9eb-44a96a402e60"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "accuracy=accuracy_score(y_pred,y_test)\n",
        "print('The accuracy is ',accuracy)\n",
        "print('F1 score is ',f1_score(y_test,y_pred,average='weighted'))\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is  0.875\n",
            "F1 score is  0.8752561647066984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32,  0,  0,  0,  3,  0,  0,  0,  0,  0],\n",
              "       [ 0, 22,  4,  0,  1,  0,  0,  1,  6,  1],\n",
              "       [ 0,  1, 32,  0,  0,  0,  0,  1,  2,  0],\n",
              "       [ 0,  0,  0, 31,  0,  0,  0,  0,  2,  4],\n",
              "       [ 0,  1,  0,  0, 30,  0,  0,  1,  0,  0],\n",
              "       [ 1,  1,  0,  0,  0, 39,  0,  0,  2,  3],\n",
              "       [ 0,  0,  0,  0,  0,  0, 29,  0,  1,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 42,  0,  0],\n",
              "       [ 0,  1,  1,  0,  0,  1,  0,  0, 33,  2],\n",
              "       [ 0,  0,  0,  0,  0,  2,  0,  1,  1, 25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JigH034MREVu",
        "colab_type": "text"
      },
      "source": [
        "## Results:\n",
        "\n",
        "### From the above results Bernoulli Naive Bayes has the best F1-score which is 0.875"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7bwOd97RUX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}